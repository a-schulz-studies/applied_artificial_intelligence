{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3862cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14e03d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Specify the path to the dataset directory\n",
    "dataset_dir = '/home/a-schulz/Projects/applied_artificial_intelligence/src/week_10/Datasets'\n",
    "target_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67ee974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image as tf_image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "# Get all images\n",
    "def read_images_from_directory(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    class_names = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for class_name in dirs:\n",
    "            class_directory = os.path.join(root, class_name)\n",
    "            for filename in os.listdir(class_directory):\n",
    "                file_path = os.path.join(class_directory, filename)\n",
    "                if os.path.isfile(file_path):\n",
    "                    img = tf_image.load_img(file_path, target_size=(224, 224))\n",
    "                    if img is not None:\n",
    "                        img = tf_image.img_to_array(img)\n",
    "                        img = np.expand_dims(img, axis=0)\n",
    "                        img = preprocess_input(img)\n",
    "                        images.append(img)\n",
    "                        labels.append(class_name)\n",
    "                        if class_name not in class_names:\n",
    "                            class_names.append(class_name)\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    class_names = np.array(class_names)\n",
    "\n",
    "    return images, labels, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "febbb89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_prefix_from_list(input_list, regex_pattern):\n",
    "    \"\"\"\n",
    "    Remove prefix from each element of the input list using the given regex pattern.\n",
    "\n",
    "    Parameters:\n",
    "        input_list (list): The list of strings from which to remove the prefix.\n",
    "        regex_pattern (str): The regular expression pattern representing the prefix to remove.\n",
    "\n",
    "    Returns:\n",
    "        list: A new list with the prefix removed from each element.\n",
    "    \"\"\"\n",
    "    return [re.sub(regex_pattern, '', element) for element in input_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8c521e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels from own dataset\n",
    "dataset_dir = \"/home/a-schulz/Projects/applied_artificial_intelligence/src/week_10/Datasets/\"\n",
    "images, labels, class_names = read_images_from_directory(dataset_dir)\n",
    "\n",
    "labels = remove_prefix_from_list(labels, r'^[0-9]+-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b866102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 568ms/step\n",
      "kelpie: 0.8813256025314331\n",
      "coyote: 0.05048876255750656\n",
      "bluetick: 0.013472615741193295\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "Ibizan_hound: 0.6635900139808655\n",
      "toy_terrier: 0.040264565497636795\n",
      "English_foxhound: 0.03564338758587837\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "parachute: 0.2394523024559021\n",
      "wing: 0.12567239999771118\n",
      "geyser: 0.08932481706142426\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "wing: 0.4148896038532257\n",
      "geyser: 0.13202735781669617\n",
      "volcano: 0.1044885665178299\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "parachute: 0.19215597212314606\n",
      "wing: 0.13615572452545166\n",
      "geyser: 0.1019660010933876\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "tiger_cat: 0.4895579516887665\n",
      "tabby: 0.3037868142127991\n",
      "Egyptian_cat: 0.19396740198135376\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "tiger_cat: 0.7226136922836304\n",
      "tabby: 0.22957421839237213\n",
      "Egyptian_cat: 0.04474480450153351\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "megalith: 0.3911474645137787\n",
      "hay: 0.0901685506105423\n",
      "stone_wall: 0.06855273246765137\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "hay: 0.2676747143268585\n",
      "fountain: 0.2384824901819229\n",
      "ostrich: 0.13512930274009705\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "teddy: 0.18077440559864044\n",
      "triceratops: 0.17558324337005615\n",
      "tench: 0.1536303162574768\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "pelican: 0.3772205710411072\n",
      "lionfish: 0.0986860916018486\n",
      "dowitcher: 0.06982645392417908\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "sports_car: 0.8325793147087097\n",
      "racer: 0.05930175259709358\n",
      "convertible: 0.03394865244626999\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "limousine: 0.2883349061012268\n",
      "cab: 0.1921895444393158\n",
      "sports_car: 0.15631471574306488\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "desktop_computer: 0.4121052622795105\n",
      "monitor: 0.2445252388715744\n",
      "desk: 0.17492689192295074\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "desktop_computer: 0.7737550139427185\n",
      "monitor: 0.07924746721982956\n",
      "screen: 0.05735252425074577\n",
      "1/1 [==============================] - 0s 433ms/step\n",
      "streetcar: 0.35302284359931946\n",
      "passenger_car: 0.2864307761192322\n",
      "steam_locomotive: 0.11745648831129074\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "passenger_car: 0.703238844871521\n",
      "electric_locomotive: 0.11959170550107956\n",
      "freight_car: 0.06888695061206818\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "flagpole: 0.08110082894563675\n",
      "obelisk: 0.07416744530200958\n",
      "cab: 0.055245839059352875\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "fountain: 0.13899289071559906\n",
      "stupa: 0.1308768093585968\n",
      "palace: 0.10186092555522919\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "maypole: 0.5142468810081482\n",
      "sarong: 0.10639039427042007\n",
      "handkerchief: 0.07574984431266785\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "football_helmet: 0.21025151014328003\n",
      "rugby_ball: 0.12675374746322632\n",
      "maypole: 0.03045741841197014\n",
      "[['kelpie', 'coyote', 'bluetick'], ['Ibizan_hound', 'toy_terrier', 'English_foxhound'], ['parachute', 'wing', 'geyser'], ['wing', 'geyser', 'volcano'], ['parachute', 'wing', 'geyser'], ['tiger_cat', 'tabby', 'Egyptian_cat'], ['tiger_cat', 'tabby', 'Egyptian_cat'], ['megalith', 'hay', 'stone_wall'], ['hay', 'fountain', 'ostrich'], ['teddy', 'triceratops', 'tench'], ['pelican', 'lionfish', 'dowitcher'], ['sports_car', 'racer', 'convertible'], ['limousine', 'cab', 'sports_car'], ['desktop_computer', 'monitor', 'desk'], ['desktop_computer', 'monitor', 'screen'], ['streetcar', 'passenger_car', 'steam_locomotive'], ['passenger_car', 'electric_locomotive', 'freight_car'], ['flagpole', 'obelisk', 'cab'], ['fountain', 'stupa', 'palace'], ['maypole', 'sarong', 'handkerchief'], ['football_helmet', 'rugby_ball', 'maypole']]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "# Load the VGG16 model\n",
    "model = VGG16(weights='imagenet')\n",
    "\n",
    "# Make predictions\n",
    "image_pred_labels = []\n",
    "for image in images:\n",
    "    preds = model.predict(image)\n",
    "    decoded_preds = decode_predictions(preds, top=3)[0]\n",
    "    vgg16_labels = []\n",
    "    # Print the top predictions\n",
    "    for _, label, prob in decoded_preds:\n",
    "        vgg16_labels.append(label)\n",
    "        print(f\"{label}: {prob}\")    \n",
    "    image_pred_labels.append(vgg16_labels)\n",
    "print(image_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "620dfcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_related_words(word_list, category):\n",
    "    related_words = set()\n",
    "    \n",
    "    # Find synsets related to the category\n",
    "    category_synsets = wn.synsets(category)\n",
    "    \n",
    "    # Iterate over the words in the list\n",
    "    for word in word_list:\n",
    "        # Calculate similarity between word and category synsets\n",
    "        max_similarity = 0\n",
    "        for synset in category_synsets:\n",
    "            for word_synset in wn.synsets(word):\n",
    "                similarity = synset.path_similarity(word_synset)\n",
    "                if similarity and similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "        \n",
    "        # Add word to related_words if similarity threshold is met\n",
    "        if max_similarity > 0.15:\n",
    "            related_words.add(word)\n",
    "    \n",
    "    return related_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c2ce37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Related words to transport:\n",
      "convertible\n",
      "cars\n",
      "vehicle\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "word_list = ['apple', 'banana', 'carrot', 'potato', 'pear','cars', 'vehicle', 'convertible']\n",
    "category = 'transport'\n",
    "\n",
    "# Find related words from the list to the category\n",
    "related_words = find_related_words(word_list, category)\n",
    "\n",
    "# Print the related words\n",
    "print(\"Related words to\", category + \":\")\n",
    "for word in related_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "420bac37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Access prediction\n",
    "# 1 if found correctly\n",
    "accessment = []\n",
    "for label_idx, label in enumerate(labels):\n",
    "    if len(find_related_words(image_pred_labels[label_idx], label)) > 0 :\n",
    "        accessment.append(1)\n",
    "    else:\n",
    "        accessment.append(0)\n",
    "print(accessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf059b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dog', ['kelpie', 'coyote', 'bluetick'], 1), ('Dog', ['Ibizan_hound', 'toy_terrier', 'English_foxhound'], 1), ('Cloud', ['parachute', 'wing', 'geyser'], 1), ('Cloud', ['wing', 'geyser', 'volcano'], 1), ('Cloud', ['parachute', 'wing', 'geyser'], 1), ('Cat', ['tiger_cat', 'tabby', 'Egyptian_cat'], 1), ('Cat', ['tiger_cat', 'tabby', 'Egyptian_cat'], 1), ('Tree', ['megalith', 'hay', 'stone_wall'], 0), ('Tree', ['hay', 'fountain', 'ostrich'], 1), ('Fisch', ['teddy', 'triceratops', 'tench'], 0), ('Fisch', ['pelican', 'lionfish', 'dowitcher'], 0), ('Car', ['sports_car', 'racer', 'convertible'], 1), ('Car', ['limousine', 'cab', 'sports_car'], 1), ('Computer', ['desktop_computer', 'monitor', 'desk'], 1), ('Computer', ['desktop_computer', 'monitor', 'screen'], 1), ('Train', ['streetcar', 'passenger_car', 'steam_locomotive'], 0), ('Train', ['passenger_car', 'electric_locomotive', 'freight_car'], 0), ('Building', ['flagpole', 'obelisk', 'cab'], 1), ('Building', ['fountain', 'stupa', 'palace'], 1), ('Sport', ['maypole', 'sarong', 'handkerchief'], 0), ('Sport', ['football_helmet', 'rugby_ball', 'maypole'], 0)]\n",
      "Accuracy:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# merge label, prediction label, accessment\n",
    "summary = list(zip(labels,image_pred_labels,accessment))\n",
    "print(summary)\n",
    "\n",
    "accuracy = accessment.count(1)/len(labels)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b597c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'have_sex', 'dearest', 'get_it_on', 'be_intimate', 'passion', 'lovemaking', 'get_laid', 'sleep_with', 'roll_in_the_hay', 'erotic_love', 'honey', 'have_intercourse', 'make_out', 'love', 'know', 'bed', 'do_it', 'dear', 'love_life', 'making_love', 'hump', 'bonk', 'bang', 'have_it_away', 'lie_with', 'eff', 'beloved', 'sleep_together', 'make_love', 'fuck', 'screw', 'sexual_love', 'jazz', 'enjoy', 'have_it_off', 'have_a_go_at_it'}\n"
     ]
    }
   ],
   "source": [
    "# Getting synonyms for words\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "synonyms = []\n",
    "\n",
    "for syn in wn.synsets(\"love\"):\n",
    "    for i in syn.lemmas():\n",
    "        synonyms.append(i.name())\n",
    "\n",
    "print(set(synonyms))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
