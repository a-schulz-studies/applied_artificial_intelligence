{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow\n",
    "# pip install opencv-python\n",
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 00:18:50.120614: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-27 00:18:50.186744: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-27 00:18:51.445536: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-07-27 00:18:52.857266: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-27 00:18:52.883300: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-07-27 00:18:53.367414: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2023-07-27 00:18:53.561777: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2023-07-27 00:18:53.679295: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2023-07-27 00:18:56.621357: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'I2.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m# Load and preprocess the input image\u001b[39;00m\n\u001b[1;32m     11\u001b[0m img_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mI2.jpg\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# Replace with the path to your image\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m img \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39;49mload_img(img_path, target_size\u001b[39m=\u001b[39;49m(\u001b[39m224\u001b[39;49m, \u001b[39m224\u001b[39;49m))\n\u001b[1;32m     13\u001b[0m x \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mimg_to_array(img)\n\u001b[1;32m     14\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(x, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/applied-artificial-intelligence-D2XDAjBL-py3.11/lib/python3.11/site-packages/keras/src/utils/image_utils.py:422\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, pathlib\u001b[39m.\u001b[39mPath):\n\u001b[1;32m    421\u001b[0m         path \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(path\u001b[39m.\u001b[39mresolve())\n\u001b[0;32m--> 422\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(path, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    423\u001b[0m         img \u001b[39m=\u001b[39m pil_image\u001b[39m.\u001b[39mopen(io\u001b[39m.\u001b[39mBytesIO(f\u001b[39m.\u001b[39mread()))\n\u001b[1;32m    424\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'I2.jpg'"
     ]
    }
   ],
   "source": [
    "# VGG19\n",
    "import numpy as np\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input, decode_predictions\n",
    "# from keras.preprocessing import image\n",
    "import keras.utils as image\n",
    "\n",
    "# Load the pre-trained VGG19 model\n",
    "model = VGG19(weights='imagenet')\n",
    "\n",
    "# Load and preprocess the input image\n",
    "img_path = 'I2.jpg'  # Replace with the path to your image\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "# Make predictions on the image\n",
    "predictions = model.predict(x)\n",
    "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
    "\n",
    "# Print the top 3 predictions\n",
    "for _, class_name, prob in decoded_predictions:\n",
    "    print(f'{class_name}: {prob}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG 16 Complex example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Specify the path to the dataset directory\n",
    "dataset_dir = '/home/a-schulz/Projects/applied_artificial_intelligence/src/week_10/Datasets'\n",
    "target_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image as tf_image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "# Get all images\n",
    "def read_images_from_directory(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    class_names = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for class_name in dirs:\n",
    "            class_directory = os.path.join(root, class_name)\n",
    "            for filename in os.listdir(class_directory):\n",
    "                file_path = os.path.join(class_directory, filename)\n",
    "                if os.path.isfile(file_path):\n",
    "                    img = tf_image.load_img(file_path, target_size=(224, 224))\n",
    "                    if img is not None:\n",
    "                        img = tf_image.img_to_array(img)\n",
    "                        img = np.expand_dims(img, axis=0)\n",
    "                        img = preprocess_input(img)\n",
    "                        images.append(img)\n",
    "                        labels.append(class_name)\n",
    "                        if class_name not in class_names:\n",
    "                            class_names.append(class_name)\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    class_names = np.array(class_names)\n",
    "\n",
    "    return images, labels, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_prefix_from_list(input_list, regex_pattern):\n",
    "    \"\"\"\n",
    "    Remove prefix from each element of the input list using the given regex pattern.\n",
    "\n",
    "    Parameters:\n",
    "        input_list (list): The list of strings from which to remove the prefix.\n",
    "        regex_pattern (str): The regular expression pattern representing the prefix to remove.\n",
    "\n",
    "    Returns:\n",
    "        list: A new list with the prefix removed from each element.\n",
    "    \"\"\"\n",
    "    return [re.sub(regex_pattern, '', element) for element in input_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels from own dataset\n",
    "dataset_dir = \"/home/a-schulz/Projects/applied_artificial_intelligence/src/week_10/Datasets/\"\n",
    "images, labels, class_names = read_images_from_directory(dataset_dir)\n",
    "\n",
    "labels = remove_prefix_from_list(labels, r'^[0-9]+-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 00:19:27.917958: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 544ms/step\n",
      "kelpie: 0.8813256025314331\n",
      "coyote: 0.05048876255750656\n",
      "bluetick: 0.013472615741193295\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "Ibizan_hound: 0.6635900139808655\n",
      "toy_terrier: 0.040264565497636795\n",
      "English_foxhound: 0.03564338758587837\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "parachute: 0.2394523024559021\n",
      "wing: 0.12567239999771118\n",
      "geyser: 0.08932481706142426\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "wing: 0.4148896038532257\n",
      "geyser: 0.13202735781669617\n",
      "volcano: 0.1044885665178299\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "parachute: 0.19215597212314606\n",
      "wing: 0.13615572452545166\n",
      "geyser: 0.1019660010933876\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "tiger_cat: 0.4895579516887665\n",
      "tabby: 0.3037868142127991\n",
      "Egyptian_cat: 0.19396740198135376\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "tiger_cat: 0.7226136922836304\n",
      "tabby: 0.22957421839237213\n",
      "Egyptian_cat: 0.04474480450153351\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "megalith: 0.3911474645137787\n",
      "hay: 0.0901685506105423\n",
      "stone_wall: 0.06855273246765137\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "hay: 0.2676747143268585\n",
      "fountain: 0.2384824901819229\n",
      "ostrich: 0.13512930274009705\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "teddy: 0.18077440559864044\n",
      "triceratops: 0.17558324337005615\n",
      "tench: 0.1536303162574768\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "pelican: 0.3772205710411072\n",
      "lionfish: 0.0986860916018486\n",
      "dowitcher: 0.06982645392417908\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "sports_car: 0.8325793147087097\n",
      "racer: 0.05930175259709358\n",
      "convertible: 0.03394865244626999\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "limousine: 0.2883349061012268\n",
      "cab: 0.1921895444393158\n",
      "sports_car: 0.15631471574306488\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "desktop_computer: 0.4121052622795105\n",
      "monitor: 0.2445252388715744\n",
      "desk: 0.17492689192295074\n",
      "1/1 [==============================] - 0s 474ms/step\n",
      "desktop_computer: 0.7737550139427185\n",
      "monitor: 0.07924746721982956\n",
      "screen: 0.05735252425074577\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "streetcar: 0.35302284359931946\n",
      "passenger_car: 0.2864307761192322\n",
      "steam_locomotive: 0.11745648831129074\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "passenger_car: 0.703238844871521\n",
      "electric_locomotive: 0.11959170550107956\n",
      "freight_car: 0.06888695061206818\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "flagpole: 0.08110082894563675\n",
      "obelisk: 0.07416744530200958\n",
      "cab: 0.055245839059352875\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "fountain: 0.13899289071559906\n",
      "stupa: 0.1308768093585968\n",
      "palace: 0.10186092555522919\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "maypole: 0.5142468810081482\n",
      "sarong: 0.10639039427042007\n",
      "handkerchief: 0.07574984431266785\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "football_helmet: 0.21025151014328003\n",
      "rugby_ball: 0.12675374746322632\n",
      "maypole: 0.03045741841197014\n",
      "[['kelpie', 'coyote', 'bluetick'], ['Ibizan_hound', 'toy_terrier', 'English_foxhound'], ['parachute', 'wing', 'geyser'], ['wing', 'geyser', 'volcano'], ['parachute', 'wing', 'geyser'], ['tiger_cat', 'tabby', 'Egyptian_cat'], ['tiger_cat', 'tabby', 'Egyptian_cat'], ['megalith', 'hay', 'stone_wall'], ['hay', 'fountain', 'ostrich'], ['teddy', 'triceratops', 'tench'], ['pelican', 'lionfish', 'dowitcher'], ['sports_car', 'racer', 'convertible'], ['limousine', 'cab', 'sports_car'], ['desktop_computer', 'monitor', 'desk'], ['desktop_computer', 'monitor', 'screen'], ['streetcar', 'passenger_car', 'steam_locomotive'], ['passenger_car', 'electric_locomotive', 'freight_car'], ['flagpole', 'obelisk', 'cab'], ['fountain', 'stupa', 'palace'], ['maypole', 'sarong', 'handkerchief'], ['football_helmet', 'rugby_ball', 'maypole']]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "# Load the VGG16 model\n",
    "model = VGG16(weights='imagenet')\n",
    "\n",
    "# Make predictions\n",
    "image_pred_labels = []\n",
    "for image in images:\n",
    "    preds = model.predict(image)\n",
    "    decoded_preds = decode_predictions(preds, top=3)[0]\n",
    "    vgg16_labels = []\n",
    "    # Print the top predictions\n",
    "    for _, label, prob in decoded_preds:\n",
    "        vgg16_labels.append(label)\n",
    "        print(f\"{label}: {prob}\")    \n",
    "    image_pred_labels.append(vgg16_labels)\n",
    "print(image_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_related_words(word_list, category):\n",
    "    related_words = set()\n",
    "    \n",
    "    # Find synsets related to the category\n",
    "    category_synsets = wn.synsets(category)\n",
    "    \n",
    "    # Iterate over the words in the list\n",
    "    for word in word_list:\n",
    "        # Calculate similarity between word and category synsets\n",
    "        max_similarity = 0\n",
    "        for synset in category_synsets:\n",
    "            for word_synset in wn.synsets(word):\n",
    "                similarity = synset.path_similarity(word_synset)\n",
    "                if similarity and similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "        \n",
    "        # Add word to related_words if similarity threshold is met\n",
    "        if max_similarity > 0.15:\n",
    "            related_words.add(word)\n",
    "    \n",
    "    return related_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Access prediction\n",
    "# 1 if found correctly\n",
    "accessment = []\n",
    "for label_idx, label in enumerate(labels):\n",
    "    if len(find_related_words(image_pred_labels[label_idx], label)) > 0 :\n",
    "        accessment.append(1)\n",
    "    else:\n",
    "        accessment.append(0)\n",
    "print(accessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dog', ['kelpie', 'coyote', 'bluetick'], 1), ('Dog', ['Ibizan_hound', 'toy_terrier', 'English_foxhound'], 1), ('Cloud', ['parachute', 'wing', 'geyser'], 1), ('Cloud', ['wing', 'geyser', 'volcano'], 1), ('Cloud', ['parachute', 'wing', 'geyser'], 1), ('Cat', ['tiger_cat', 'tabby', 'Egyptian_cat'], 1), ('Cat', ['tiger_cat', 'tabby', 'Egyptian_cat'], 1), ('Tree', ['megalith', 'hay', 'stone_wall'], 0), ('Tree', ['hay', 'fountain', 'ostrich'], 1), ('Fisch', ['teddy', 'triceratops', 'tench'], 0), ('Fisch', ['pelican', 'lionfish', 'dowitcher'], 0), ('Car', ['sports_car', 'racer', 'convertible'], 1), ('Car', ['limousine', 'cab', 'sports_car'], 1), ('Computer', ['desktop_computer', 'monitor', 'desk'], 1), ('Computer', ['desktop_computer', 'monitor', 'screen'], 1), ('Train', ['streetcar', 'passenger_car', 'steam_locomotive'], 0), ('Train', ['passenger_car', 'electric_locomotive', 'freight_car'], 0), ('Building', ['flagpole', 'obelisk', 'cab'], 1), ('Building', ['fountain', 'stupa', 'palace'], 1), ('Sport', ['maypole', 'sarong', 'handkerchief'], 0), ('Sport', ['football_helmet', 'rugby_ball', 'maypole'], 0)]\n",
      "Accuracy:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# merge label, prediction label, accessment\n",
    "summary = list(zip(labels,image_pred_labels,accessment))\n",
    "print(summary)\n",
    "\n",
    "accuracy = accessment.count(1)/len(labels)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting synonyms for words\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "synonyms = []\n",
    "\n",
    "for syn in wn.synsets(\"love\"):\n",
    "    for i in syn.lemmas():\n",
    "        synonyms.append(i.name())\n",
    "\n",
    "print(set(synonyms))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applied-artificial-intelligence-D2XDAjBL-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
